[2025-12-04 14:52:06,405] [INFO] 日志已写入：./logs/msl/MambaTSAD_20251204_145206.log
[2025-12-04 14:52:06,407] [INFO] 参数配置：Namespace(dataset='msl', processed_root='./dataset/MSL', log_dir='./logs/msl', win_size=100, train_stride=1, test_stride=5, batch_size=64, epochs=50, lr=0.0005, weight_decay=0.005, seed=42, no_amp=True, max_grad_norm=1.0, patience=8, no_point_adjust=False)
[2025-12-04 14:52:06,494] [INFO] MSL 多通道数据集构建完成：entities=['C-1', 'C-2', 'D-14', 'D-15', 'D-16', 'F-4', 'F-5', 'F-7', 'F-8', 'M-1', 'M-2', 'M-3', 'M-4', 'M-5', 'M-6', 'M-7', 'P-10', 'P-11', 'P-14', 'P-15', 'S-2', 'T-12', 'T-13', 'T-4', 'T-5', 'T-8', 'T-9'], input_dim=55, len(train)=55644, len(test)=14223
[2025-12-04 14:52:08,533] [INFO] 模型结构：
MambaTSAD(
  (encoder): Linear(in_features=55, out_features=128, bias=True)
  (level1): ModuleList(
    (0-1): 2 x LSSBlockTS(
      (global_layers): ModuleList(
        (0-1): 2 x BiMambaBlock(
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mamba_fwd): Mamba(
            (in_proj): Linear(in_features=128, out_features=512, bias=False)
            (conv1d): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
            (act): SiLU()
            (x_proj): Linear(in_features=256, out_features=40, bias=False)
            (dt_proj): Linear(in_features=8, out_features=256, bias=True)
            (out_proj): Linear(in_features=256, out_features=128, bias=False)
          )
          (mamba_bwd): Mamba(
            (in_proj): Linear(in_features=128, out_features=512, bias=False)
            (conv1d): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
            (act): SiLU()
            (x_proj): Linear(in_features=256, out_features=40, bias=False)
            (dt_proj): Linear(in_features=8, out_features=256, bias=True)
            (out_proj): Linear(in_features=256, out_features=128, bias=False)
          )
          (ffn): Sequential(
            (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (1): Linear(in_features=128, out_features=512, bias=True)
            (2): GELU(approximate='none')
            (3): Dropout(p=0.01, inplace=False)
            (4): Linear(in_features=512, out_features=128, bias=True)
          )
          (dropout): Dropout(p=0.01, inplace=False)
        )
      )
      (local_branches): ModuleList(
        (0): LocalConvBlock1D(
          (block): Sequential(
            (0): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
            (1): InstanceNorm1d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): SiLU()
            (3): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,), groups=128)
            (4): InstanceNorm1d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (5): SiLU()
            (6): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
          )
        )
        (1): LocalConvBlock1D(
          (block): Sequential(
            (0): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
            (1): InstanceNorm1d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): SiLU()
            (3): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,), groups=128)
            (4): InstanceNorm1d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (5): SiLU()
            (6): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
          )
        )
      )
      (proj): Linear(in_features=384, out_features=128, bias=True)
    )
  )
  (level2): ModuleList(
    (0-1): 2 x LSSBlockTS(
      (global_layers): ModuleList(
        (0-1): 2 x BiMambaBlock(
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mamba_fwd): Mamba(
            (in_proj): Linear(in_features=128, out_features=512, bias=False)
            (conv1d): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
            (act): SiLU()
            (x_proj): Linear(in_features=256, out_features=40, bias=False)
            (dt_proj): Linear(in_features=8, out_features=256, bias=True)
            (out_proj): Linear(in_features=256, out_features=128, bias=False)
          )
          (mamba_bwd): Mamba(
            (in_proj): Linear(in_features=128, out_features=512, bias=False)
            (conv1d): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
            (act): SiLU()
            (x_proj): Linear(in_features=256, out_features=40, bias=False)
            (dt_proj): Linear(in_features=8, out_features=256, bias=True)
            (out_proj): Linear(in_features=256, out_features=128, bias=False)
          )
          (ffn): Sequential(
            (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (1): Linear(in_features=128, out_features=512, bias=True)
            (2): GELU(approximate='none')
            (3): Dropout(p=0.01, inplace=False)
            (4): Linear(in_features=512, out_features=128, bias=True)
          )
          (dropout): Dropout(p=0.01, inplace=False)
        )
      )
      (local_branches): ModuleList(
        (0): LocalConvBlock1D(
          (block): Sequential(
            (0): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
            (1): InstanceNorm1d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): SiLU()
            (3): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,), groups=128)
            (4): InstanceNorm1d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (5): SiLU()
            (6): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
          )
        )
        (1): LocalConvBlock1D(
          (block): Sequential(
            (0): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
            (1): InstanceNorm1d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): SiLU()
            (3): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,), groups=128)
            (4): InstanceNorm1d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (5): SiLU()
            (6): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
          )
        )
      )
      (proj): Linear(in_features=384, out_features=128, bias=True)
    )
  )
  (level3): ModuleList(
    (0-1): 2 x LSSBlockTS(
      (global_layers): ModuleList(
        (0-1): 2 x BiMambaBlock(
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mamba_fwd): Mamba(
            (in_proj): Linear(in_features=128, out_features=512, bias=False)
            (conv1d): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
            (act): SiLU()
            (x_proj): Linear(in_features=256, out_features=40, bias=False)
            (dt_proj): Linear(in_features=8, out_features=256, bias=True)
            (out_proj): Linear(in_features=256, out_features=128, bias=False)
          )
          (mamba_bwd): Mamba(
            (in_proj): Linear(in_features=128, out_features=512, bias=False)
            (conv1d): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
            (act): SiLU()
            (x_proj): Linear(in_features=256, out_features=40, bias=False)
            (dt_proj): Linear(in_features=8, out_features=256, bias=True)
            (out_proj): Linear(in_features=256, out_features=128, bias=False)
          )
          (ffn): Sequential(
            (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (1): Linear(in_features=128, out_features=512, bias=True)
            (2): GELU(approximate='none')
            (3): Dropout(p=0.01, inplace=False)
            (4): Linear(in_features=512, out_features=128, bias=True)
          )
          (dropout): Dropout(p=0.01, inplace=False)
        )
      )
      (local_branches): ModuleList(
        (0): LocalConvBlock1D(
          (block): Sequential(
            (0): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
            (1): InstanceNorm1d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): SiLU()
            (3): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,), groups=128)
            (4): InstanceNorm1d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (5): SiLU()
            (6): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
          )
        )
        (1): LocalConvBlock1D(
          (block): Sequential(
            (0): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
            (1): InstanceNorm1d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): SiLU()
            (3): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,), groups=128)
            (4): InstanceNorm1d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (5): SiLU()
            (6): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
          )
        )
      )
      (proj): Linear(in_features=384, out_features=128, bias=True)
    )
  )
  (decoder): Linear(in_features=128, out_features=55, bias=True)
)
[2025-12-04 14:52:08,534] [INFO] ========== Epoch 1/50 ==========
[2025-12-04 14:53:13,837] [INFO] 本 epoch 平均训练损失: 0.753211
[2025-12-04 14:53:42,456] [INFO] [Eval] F1=0.8728, P=0.8923, R=0.8542, AUC=0.5453, thr=2.028017, point_adjust=True
[2025-12-04 14:53:42,562] [INFO] 发现更优模型，已保存至 ./logs/msl/best_model.pt
[2025-12-04 14:53:42,823] [INFO] 已保存可视化图：./logs/msl/scores_epoch1.png
[2025-12-04 14:53:42,823] [INFO] ========== Epoch 2/50 ==========
[2025-12-04 14:54:47,729] [INFO] 本 epoch 平均训练损失: 0.695081
[2025-12-04 14:55:16,844] [INFO] [Eval] F1=0.8711, P=0.8886, R=0.8542, AUC=0.5471, thr=1.879688, point_adjust=True
[2025-12-04 14:55:17,100] [INFO] 已保存可视化图：./logs/msl/scores_epoch2.png
[2025-12-04 14:55:17,100] [INFO] ========== Epoch 3/50 ==========
[2025-12-04 14:56:19,283] [INFO] 本 epoch 平均训练损失: 0.688566
[2025-12-04 14:56:47,916] [INFO] [Eval] F1=0.8710, P=0.8884, R=0.8542, AUC=0.5500, thr=1.866307, point_adjust=True
[2025-12-04 14:56:48,163] [INFO] 已保存可视化图：./logs/msl/scores_epoch3.png
[2025-12-04 14:56:48,163] [INFO] ========== Epoch 4/50 ==========
[2025-12-04 14:57:52,816] [INFO] 本 epoch 平均训练损失: 0.685432
[2025-12-04 14:58:22,053] [INFO] [Eval] F1=0.8703, P=0.9014, R=0.8414, AUC=0.5525, thr=2.385065, point_adjust=True
[2025-12-04 14:58:22,305] [INFO] 已保存可视化图：./logs/msl/scores_epoch4.png
[2025-12-04 14:58:22,305] [INFO] ========== Epoch 5/50 ==========
[2025-12-04 14:59:27,440] [INFO] 本 epoch 平均训练损失: 0.683391
[2025-12-04 14:59:55,954] [INFO] [Eval] F1=0.8693, P=0.8947, R=0.8454, AUC=0.5539, thr=1.932260, point_adjust=True
[2025-12-04 14:59:56,207] [INFO] 已保存可视化图：./logs/msl/scores_epoch5.png
[2025-12-04 14:59:56,207] [INFO] ========== Epoch 6/50 ==========
[2025-12-04 15:01:01,212] [INFO] 本 epoch 平均训练损失: 0.683075
[2025-12-04 15:01:29,843] [INFO] [Eval] F1=0.8710, P=0.8884, R=0.8542, AUC=0.5531, thr=1.857595, point_adjust=True
[2025-12-04 15:01:30,096] [INFO] 已保存可视化图：./logs/msl/scores_epoch6.png
[2025-12-04 15:01:30,096] [INFO] ========== Epoch 7/50 ==========
[2025-12-04 15:02:34,214] [INFO] 本 epoch 平均训练损失: 0.683250
[2025-12-04 15:03:02,981] [INFO] [Eval] F1=0.8711, P=0.8985, R=0.8454, AUC=0.5538, thr=1.996214, point_adjust=True
[2025-12-04 15:03:03,233] [INFO] 已保存可视化图：./logs/msl/scores_epoch7.png
[2025-12-04 15:03:03,233] [INFO] ========== Epoch 8/50 ==========
[2025-12-04 15:04:07,868] [INFO] 本 epoch 平均训练损失: 0.681063
[2025-12-04 15:04:36,917] [INFO] [Eval] F1=0.8709, P=0.8882, R=0.8542, AUC=0.5560, thr=1.824609, point_adjust=True
[2025-12-04 15:04:37,173] [INFO] 已保存可视化图：./logs/msl/scores_epoch8.png
[2025-12-04 15:04:37,173] [INFO] ========== Epoch 9/50 ==========
[2025-12-04 15:05:42,190] [INFO] 本 epoch 平均训练损失: 0.680693
[2025-12-04 15:06:10,633] [INFO] [Eval] F1=0.8708, P=0.8881, R=0.8542, AUC=0.5552, thr=1.860998, point_adjust=True
[2025-12-04 15:06:10,633] [INFO] 早停触发：连续 8 个 epoch F1 未提升，在第 9 个 epoch 停止训练。
[2025-12-04 15:06:10,634] [INFO] 训练结束，最佳 F1=0.8728, 最佳指标={'precision': 0.8922663080014899, 'recall': 0.8542364151418308, 'f1': 0.8728373083358714, 'auc': 0.5452875432406408, 'threshold': 2.0280169904232026, 'use_point_adjust': True}
